**What did you learn from implementing a multi-agent workflow?**
I learned how different types of prompts can change the quality of the agents’ responses. At the beginning, I gave very short instructions and not enough context. The results were confusing and sometimes incomplete. Later, I started to include more details about the desired output, such as how the information should be organized or summarized. After doing that, the responses became more accurate and easier to follow. This helped me understand how important it is to give enough structure and context for the AI to work well. I also focused a lot on improving the Review Agent because it needed to check the quality of the Planner’s work. I fine-tuned it more carefully so that it could detect mistakes and make the output clearer for the user.

**Challenges faced and how you addressed them.**
The main challenge was to make sure that the final output was clear for the user. At first, the agents repeated the same information in several places or mixed too many ideas together. To solve this, I added clearer instructions about the format and asked the Review Agent to summarize the plan. Another challenge was to keep the results realistic.

**Any creative ideas, variations, or design choices (e.g., persona roles, prompt design)**
I think it would be useful to include the user’s location as part of the input to make the prompt more realistic and context-aware. Regarding the agent roles, showing both outputs to the user can be confusing. For a real product, it would be better to only show the Reviewer’s final output, I feel like the user doesn’t need to see the behind-the-scenes process.

**Use of AI**
I used AI to review my grammar and writing. 